{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "from time import time\n",
    "import pickle\n",
    "import cv2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.layers.merge import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../model_weights/model_9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_temp = ResNet50(weights=\"imagenet\",input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new model, by removing the last output layer\n",
    "model_resnet = Model(model_temp.input,model_temp.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "def preprocess_img(img):\n",
    "    img = image.load_img(img,target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    # As the input to a ResNet is a 4D tensor.Therefore expanding the size (1,224,224,3)\n",
    "    img = np.expand_dims(img,axis=0) \n",
    "     #Normalisation\n",
    "    img = preprocess_input(img)    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(img):\n",
    "    img = preprocess_img(img)\n",
    "    feature_vector = model_resnet.predict(img)\n",
    "    feature_vector = feature_vector.reshape((1,2048))\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../saved/index_to_word.pkl', 'rb') as f:\n",
    "    index_to_word = pickle.load(f)\n",
    "    \n",
    "with open('../saved/word_to_index.pkl', 'rb') as f:\n",
    "    word_to_index = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting output\n",
    "def predict_caption(photo):\n",
    "    in_text = \"startseq\"\n",
    "    max_len = 35\n",
    "    for i in range(max_len):\n",
    "        sequence = [word_to_index[w] for w in in_text.split() if w in word_to_index]\n",
    "        sequence = pad_sequences([sequence],maxlen = max_len,padding='post')\n",
    "        ypred = model.predict([photo,sequence])\n",
    "        ypred = ypred.argmax() #greedy sampling of the words.\n",
    "        word = index_to_word[ypred]\n",
    "        in_text += ' ' + word\n",
    "        \n",
    "        if word == \"endseq\":\n",
    "            break\n",
    "    final_caption = in_text.split()[1:-1] # Removing startseq and endseq from the captions\n",
    "    final_caption = ' '.join(final_caption)\n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encode_image(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption = predict_caption(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two men in black outfits are standing in front of the ice\n"
     ]
    }
   ],
   "source": [
    "print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
